{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxsByW53sqA9WnQE1QDlrE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrahanG/MantraShastra/blob/main/MantraShastra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH_1yDwiL2RN",
        "outputId": "10a9f377-962f-49cb-c00f-0dfa4651b55d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Keywords  \\\n",
            "0  Amba Bhavani Sharade, Devotional Song, Sri Gan...   \n",
            "1  Sampoorna Bhagavad Gita Parayana, Ganapathy Sa...   \n",
            "2      Solution for Financial Problems, Sundarakanda   \n",
            "3  Unrevealed Secrets, Chandiyagam, Ancient Secre...   \n",
            "4     Science of Bhakti yoga, Devotee and Deal Maker   \n",
            "\n",
            "                                  Processed_Keywords  \n",
            "0  amba bhavani sharade, devotional song, sri gan...  \n",
            "1  sampoorna bhagavad gita parayana, ganapathy sa...  \n",
            "2      solution for financial problems, sundarakanda  \n",
            "3  unrevealed secrets, chandiyagam, ancient secre...  \n",
            "4     science of bhakti yoga, devotee and deal maker  \n",
            "TF-IDF Matrix Shape: (141, 355)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "file_path = \"/content/data.xlsx\"\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load keywords from Sheet1 and remove duplicates\n",
        "df_keywords = xls.parse(\"Sheet1\")[[\"Keywords\"]].drop_duplicates()\n",
        "\n",
        "# Drop missing values\n",
        "df_keywords = df_keywords.dropna()\n",
        "\n",
        "# Convert keywords to lowercase and remove extra spaces\n",
        "df_keywords[\"Processed_Keywords\"] = df_keywords[\"Keywords\"].str.lower().str.strip()\n",
        "\n",
        "# Convert keywords to TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df_keywords[\"Processed_Keywords\"])\n",
        "\n",
        "# Display results\n",
        "print(df_keywords.head())\n",
        "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Initialize KNN model (using Cosine similarity)\n",
        "knn = NearestNeighbors(n_neighbors=5, metric=\"cosine\")\n",
        "knn.fit(tfidf_matrix)\n",
        "\n",
        "# Function to get similar keywords\n",
        "def get_similar_keywords(keyword, top_n=5):\n",
        "    query_vector = vectorizer.transform([keyword])  # Convert input keyword to vector\n",
        "    distances, indices = knn.kneighbors(query_vector, n_neighbors=top_n)  # Find neighbors\n",
        "    similar_keywords = df_keywords.iloc[indices[0]][\"Processed_Keywords\"].values\n",
        "    return list(zip(similar_keywords, distances[0]))\n",
        "\n",
        "# Example usage\n",
        "keyword_input = \"sleep\"\n",
        "similar_words = get_similar_keywords(keyword_input)\n",
        "print(\"Similar Keywords:\", similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoOw5etXNkoL",
        "outputId": "6d238b11-14a7-4188-d82c-d8fcad029f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar Keywords: [('hanuman mantra for good sleep', 0.44672407672375125), (\"mantra to chant before bed for a good night's sleep\", 0.6266186293154306), ('mantra for good health and happiness, kalki purana sloka', 1.0), ('wealtth, sri rama navami', 1.0), ('relief from all problems', 1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def mean_reciprocal_rank(results, relevant_keywords):\n",
        "    ranks = []\n",
        "    for i, (word, _) in enumerate(results):\n",
        "        if word in relevant_keywords:\n",
        "            ranks.append(1 / (i + 1))  # 1 / rank position\n",
        "    return np.mean(ranks) if ranks else 0\n",
        "\n",
        "# Example evaluation\n",
        "relevant_keywords = [\"relif\",\"rest\"]  # Expected similar terms\n",
        "mrr_score = mean_reciprocal_rank(similar_words, relevant_keywords)\n",
        "print(\"MRR Score:\", mrr_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d66zutXNnUM",
        "outputId": "71229c86-6c85-44a2-8522-9a6f5598c6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR Score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_input = \"sleep\"\n",
        "similar_words = get_similar_keywords(keyword_input)\n",
        "\n",
        "print(\"Retrieved Similar Keywords:\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"{word} (Similarity Score: {score})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXilIEySOy80",
        "outputId": "ce1cde91-53e5-4f67-dc0f-f8c4ebc27891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Similar Keywords:\n",
            "hanuman mantra for good sleep (Similarity Score: 0.44672407672375125)\n",
            "mantra to chant before bed for a good night's sleep (Similarity Score: 0.6266186293154306)\n",
            "mantra for good health and happiness, kalki purana sloka (Similarity Score: 1.0)\n",
            "wealtth, sri rama navami (Similarity Score: 1.0)\n",
            "relief from all problems (Similarity Score: 1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "relevant_keywords = [word.lower().strip() for word in relevant_keywords]\n",
        "retrieved_keywords = [word.lower().strip() for word, _ in similar_words]\n",
        "\n",
        "print(\"Retrieved:\", retrieved_keywords)\n",
        "print(\"Expected:\", relevant_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3llMbGyPHND",
        "outputId": "c2b91f83-86d5-4324-e942-deed04661f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved: ['hanuman mantra for good sleep', \"mantra to chant before bed for a good night's sleep\", 'mantra for good health and happiness, kalki purana sloka', 'wealtth, sri rama navami', 'relief from all problems']\n",
            "Expected: ['relif', 'rest']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_reciprocal_rank(results, relevant_keywords):\n",
        "    ranks = []\n",
        "    for i, (word, _) in enumerate(results):\n",
        "        if word in relevant_keywords:  # Ensure correct string matching\n",
        "            ranks.append(1 / (i + 1))\n",
        "    return np.mean(ranks) if ranks else 0\n",
        "\n",
        "# Example usage\n",
        "relevant_keywords = [\"health\"]  # Ensure exact matches\n",
        "mrr_score = mean_reciprocal_rank(similar_words, relevant_keywords)\n",
        "print(\"MRR Score:\", mrr_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktb2S7x5PNr4",
        "outputId": "8b3f9875-d102-4e1f-a471-00383a64c137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR Score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load Excel file\n",
        "file_path = \"/content/data.xlsx\"  # Update with your actual file path\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load keywords from Sheet1 and remove duplicates & missing values\n",
        "df_keywords = xls.parse(\"Sheet1\")[[\"Keywords\"]].drop_duplicates().dropna()\n",
        "\n",
        "# Convert keywords to lowercase and clean text\n",
        "df_keywords[\"Processed_Keywords\"] = df_keywords[\"Keywords\"].str.lower().str.strip()\n",
        "\n",
        "# Convert cleaned keywords into TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df_keywords[\"Processed_Keywords\"])\n",
        "\n",
        "# Initialize KNN model with Cosine Similarity\n",
        "knn = NearestNeighbors(n_neighbors=5, metric=\"manhattan\")\n",
        "knn.fit(tfidf_matrix)\n",
        "\n",
        "# Function to find similar keywords\n",
        "def get_similar_keywords(keyword, top_n=5):\n",
        "    query_vector = vectorizer.transform([keyword.lower().strip()])  # Convert input keyword to vector\n",
        "    distances, indices = knn.kneighbors(query_vector, n_neighbors=top_n)  # Find neighbors\n",
        "    similar_keywords = df_keywords.iloc[indices[0]][\"Processed_Keywords\"].values\n",
        "    return list(zip(similar_keywords, distances[0]))\n",
        "\n",
        "# Function to calculate Mean Reciprocal Rank (MRR)\n",
        "def mean_reciprocal_rank(results, relevant_keywords):\n",
        "    relevant_keywords = [word.lower().strip() for word in relevant_keywords]\n",
        "    ranks = []\n",
        "    for i, (word, _) in enumerate(results):\n",
        "        if word in relevant_keywords:\n",
        "            ranks.append(1 / (i + 1))  # 1 / rank position\n",
        "    return np.mean(ranks) if ranks else 0\n",
        "\n",
        "# Example usage\n",
        "keyword_input = \"health\"\n",
        "similar_words = get_similar_keywords(keyword_input)\n",
        "\n",
        "# Print retrieved similar keywords\n",
        "print(\"\\nðŸ”¹ Retrieved Similar Keywords:\")\n",
        "for word, score in similar_words:\n",
        "    print(f\"{word} (Similarity Score: {score:.4f})\")\n",
        "\n",
        "# Example evaluation\n",
        "relevant_keywords = [\"health\",\"wellness\"]  # Expected relevant keywords\n",
        "mrr_score = mean_reciprocal_rank(similar_words, relevant_keywords)\n",
        "print(f\"\\nðŸ“Œ MRR Score: {mrr_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOkc3p50PWpH",
        "outputId": "0d4e6752-b1df-4d50-93b7-07f050157f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Retrieved Similar Keywords:\n",
            "health (Similarity Score: 0.0000)\n",
            "children's health (Similarity Score: 1.1023)\n",
            "thiruppavai (Similarity Score: 2.0000)\n",
            "depression (Similarity Score: 2.0000)\n",
            "health, wealth, manifestation, influence (Similarity Score: 2.1819)\n",
            "\n",
            "ðŸ“Œ MRR Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load Pretrained Word2Vec model (Google's Word2Vec)\n",
        "word_vectors = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
        "\n",
        "# Get word similarity\n",
        "word1, word2 = \"health\",\"wellness\"\n",
        "similarity = word_vectors.similarity(word1, word2)\n",
        "print(f\"Similarity between {word1} and {word2}: {similarity}\")"
      ],
      "metadata": {
        "id": "i6ygRwo6QWOC",
        "outputId": "bb299f4d-7b03-4e01-fa4a-deab9cc0a7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5b2d69c5ba9e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load Pretrained Word2Vec model (Google's Word2Vec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GoogleNews-vectors-negative300.bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get word similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \"\"\"\n\u001b[0;32m-> 1719\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1720\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             \u001b[0;31m# deduce both vocab_size & vector_size from 1st pass over file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'"
          ]
        }
      ]
    }
  ]
}